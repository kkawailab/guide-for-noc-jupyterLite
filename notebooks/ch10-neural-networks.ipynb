{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfb5cccf",
   "metadata": {},
   "source": [
    "# 第10章 — ニューラルネットワーク\n",
    "\n",
    "- パーセプトロンは重み付き和に活性化をかけ、層を重ねて関数を近似する。\n",
    "- 学習では損失の勾配降下で重みを更新する。\n",
    "- 非線形活性化（ReLUやシグモイド）が曲線的な決定境界を表現する。\n",
    "- データの正規化と小さめの学習率が安定性を高める。\n",
    "\n",
    "試してみよう: 活性化をReLUに変えたり、OR/XORを学習して（XORは中間層が必要）挙動を試す。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d07e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# パーセプトロンの定義とシグモイド活性化\n",
    "import math\n",
    "import random\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "\n",
    "class Perceptron:\n",
    "    def __init__(self, w, b=0.0, lr=0.1):\n",
    "        self.w = w\n",
    "        self.b = b\n",
    "        self.lr = lr\n",
    "\n",
    "    def predict(self, x1, x2):\n",
    "        z = self.w[0] * x1 + self.w[1] * x2 + self.b\n",
    "        return sigmoid(z)\n",
    "\n",
    "    def train(self, data, epochs=20):\n",
    "        for _ in range(epochs):\n",
    "            for x1, x2, label in data:\n",
    "                pred = self.predict(x1, x2)\n",
    "                error = label - pred\n",
    "                self.w[0] += self.lr * error * x1\n",
    "                self.w[1] += self.lr * error * x2\n",
    "                self.b += self.lr * error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36643626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANDゲートのデータで学習と推論\n",
    "samples = [\n",
    "    (0, 0, 0),\n",
    "    (0, 1, 0),\n",
    "    (1, 0, 0),\n",
    "    (1, 1, 1),\n",
    "]\n",
    "\n",
    "p = Perceptron([0.1, 0.1], b=-0.1, lr=0.5)\n",
    "p.train(samples, epochs=30)\n",
    "\n",
    "for x1, x2, _ in samples:\n",
    "    print((x1, x2), \"->\", round(p.predict(x1, x2), 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cddcc1",
   "metadata": {},
   "source": [
    "### 追加例: 2層パーセプトロンでXOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf612d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2層パーセプトロン(MLP)の定義\n",
    "def dsigmoid(y):\n",
    "    return y * (1 - y)\n",
    "\n",
    "\n",
    "class MLP:\n",
    "    def __init__(self):\n",
    "        random.seed(0)\n",
    "        self.w1 = [[random.uniform(-1, 1) for _ in range(2)] for _ in range(2)]\n",
    "        self.b1 = [0.0, 0.0]\n",
    "        self.w2 = [random.uniform(-1, 1) for _ in range(2)]\n",
    "        self.b2 = 0.0\n",
    "        self.lr = 0.5\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        h1 = sigmoid(self.w1[0][0] * x1 + self.w1[0][1] * x2 + self.b1[0])\n",
    "        h2 = sigmoid(self.w1[1][0] * x1 + self.w1[1][1] * x2 + self.b1[1])\n",
    "        out = sigmoid(self.w2[0] * h1 + self.w2[1] * h2 + self.b2)\n",
    "        return (h1, h2), out\n",
    "\n",
    "    def train(self, data, epochs=5000):\n",
    "        for _ in range(epochs):\n",
    "            for x1, x2, label in data:\n",
    "                (h1, h2), out = self.forward(x1, x2)\n",
    "                error = label - out\n",
    "                d_out = error * dsigmoid(out)\n",
    "                d_h1 = d_out * self.w2[0] * dsigmoid(h1)\n",
    "                d_h2 = d_out * self.w2[1] * dsigmoid(h2)\n",
    "                self.w2[0] += self.lr * d_out * h1\n",
    "                self.w2[1] += self.lr * d_out * h2\n",
    "                self.b2 += self.lr * d_out\n",
    "                self.w1[0][0] += self.lr * d_h1 * x1\n",
    "                self.w1[0][1] += self.lr * d_h1 * x2\n",
    "                self.w1[1][0] += self.lr * d_h2 * x1\n",
    "                self.w1[1][1] += self.lr * d_h2 * x2\n",
    "                self.b1[0] += self.lr * d_h1\n",
    "                self.b1[1] += self.lr * d_h2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568c7724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XORデータをMLPに学習させて出力を確認\n",
    "mlp = MLP()\n",
    "data = [(0, 0, 0), (0, 1, 1), (1, 0, 1), (1, 1, 0)]\n",
    "mlp.train(data, epochs=3000)\n",
    "\n",
    "for x1, x2, label in data:\n",
    "    (_, _), out = mlp.forward(x1, x2)\n",
    "    print((x1, x2), \"->\", round(out, 3), \"label\", label)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
